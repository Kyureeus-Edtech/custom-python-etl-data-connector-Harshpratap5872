# import requests
# import pandas as pd
# from pymongo import MongoClient
# from io import StringIO

# CSV_URL = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv"
# MONGO_URI = "mongodb://localhost:27017/"
# DB_NAME = "exploitdb"
# COLLECTION_NAME = "exploits"

# def extract_csv(url):
#     print("Downloading CSV...")
#     response = requests.get(url)
#     response.raise_for_status()
#     return response.text

# def load_dataframe(csv_text):
#     print("Loading CSV into DataFrame...")
#     return pd.read_csv(StringIO(csv_text))

# def transform_data(df):
#     print("Transforming data...")

#     # Ensure all date columns are datetime
#     date_cols = ['date_published', 'date_added', 'date_updated']
#     for col in date_cols:
#         if col in df.columns:
#             df[col] = pd.to_datetime(df[col], errors='coerce')

#     # Convert NaT to None and pandas Timestamp to Python datetime
#     for col in date_cols:
#         if col in df.columns:
#             df[col] = df[col].apply(lambda x: x.to_pydatetime() if pd.notnull(x) else None)

#     # Replace remaining NaN and NaT with None
#     df = df.replace({pd.NaT: None}).where(pd.notnull(df), None)

#     # Return clean list of records
#     return df.to_dict(orient='records')

# def load_to_mongo(records):
#     print("Loading into MongoDB...")
#     client = MongoClient(MONGO_URI)
#     db = client[DB_NAME]
#     collection = db[COLLECTION_NAME]

#     # Optional: Drop old data
#     collection.delete_many({})

#     # Insert in batches
#     if records:
#         collection.insert_many(records)

#     print(f"Inserted {len(records)} records.")

# def main():
#     csv_text = extract_csv(CSV_URL)
#     df = load_dataframe(csv_text)
#     records = transform_data(df)
#     load_to_mongo(records)

# if __name__ == "__main__":
#     main()


import requests
import pandas as pd
from pymongo import MongoClient
from io import StringIO
import time
import logging

CSV_URL = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv"
MONGO_URI = "mongodb://localhost:27017/"
DB_NAME = "exploitdb"
COLLECTION_NAME = "exploits"

logging.basicConfig(level=logging.INFO)

def extract_csv(url, retries=3, delay=5):
    print("Downloading CSV...")
    for attempt in range(retries):
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            return response.text
        except requests.exceptions.RequestException as e:
            logging.error(f"Download failed (attempt {attempt+1}/{retries}): {e}")
            if attempt < retries - 1:
                time.sleep(delay)
            else:
                raise

def load_dataframe(csv_text):
    print("Loading CSV into DataFrame...")
    try:
        df = pd.read_csv(StringIO(csv_text))
        return df
    except Exception as e:
        logging.error(f"Failed to load CSV: {e}")
        raise

def transform_data(df):
    print("Transforming data...")
    date_cols = ['date_published', 'date_added', 'date_updated']
    for col in date_cols:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
            df[col] = df[col].apply(lambda x: x.to_pydatetime() if pd.notnull(x) else None)
    df = df.replace({pd.NaT: None}).where(pd.notnull(df), None)
    # Validate required fields
    valid_records = []
    for rec in df.to_dict(orient='records'):
        if rec.get('id') is not None:  # Example: require 'id' field
            valid_records.append(rec)
        else:
            logging.warning(f"Skipping record with missing id: {rec}")
    return valid_records

def load_to_mongo(records):
    print("Loading into MongoDB...")
    try:
        client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
        db = client[DB_NAME]
        collection = db[COLLECTION_NAME]
        collection.delete_many({})
        if records:
            collection.insert_many(records)
        print(f"Inserted {len(records)} records.")
    except Exception as e:
        logging.error(f"MongoDB error: {e}")
        raise

def main():
    try:
        csv_text = extract_csv(CSV_URL)
        df = load_dataframe(csv_text)
        records = transform_data(df)
        load_to_mongo(records)
    except Exception as e:
        logging.error(f"Pipeline failed: {e}")

if __name__ == "__main__":
    main()